{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------------------------------------  10.0/10.1 MB 61.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 48.4 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Downloading safetensors-0.4.5-cp310-none-win_amd64.whl (285 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 45.3 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 safetensors-0.4.5 tokenizers-0.21.0 transformers-4.47.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import time\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from typing import List\n",
    "import string\n",
    "\n",
    "path = kagglehub.dataset_download(\"trainingdatapro/ocr-receipts-text-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gta76\\Desktop\\project\\ml-project\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\gta76\\.cache\\huggingface\\hub\\models--microsoft--trocr-base-printed. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.47.1\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = [['BANANAS', 'FRAP'],\n",
    " ['R',\n",
    "  'CARROTS',\n",
    "  'SHREDDED',\n",
    "  '10',\n",
    "  'OZ',\n",
    "  'R',\n",
    "  'CUCUMBERS',\n",
    "  'PERSIAN',\n",
    "  '1',\n",
    "  'LB',\n",
    "  'TOMATOES',\n",
    "  'CRUSHED',\n",
    "  'NO',\n",
    "  'SALT',\n",
    "  'TOMATOES',\n",
    "  'WHOLE',\n",
    "  'NO',\n",
    "  'SALT',\n",
    "  'W',\n",
    "  'BASIL',\n",
    "  'ORGANIC',\n",
    "  'OLD',\n",
    "  'FASHIONED',\n",
    "  'OATMEAL',\n",
    "  'MINI',\n",
    "  'PEARL',\n",
    "  'TOMATOES',\n",
    "  'PKG',\n",
    "  'SHREDDED',\n",
    "  'MOZZARELLA',\n",
    "  'LITE',\n",
    "  'T',\n",
    "  'EGGS',\n",
    "  '1',\n",
    "  'DOZ',\n",
    "  'ORGANIC',\n",
    "  'BROWN',\n",
    "  'BEANS',\n",
    "  'GARBANZO',\n",
    "  'SPROUTED',\n",
    "  'CA',\n",
    "  'STYLE',\n",
    "  'A',\n",
    "  'AVOCADOS',\n",
    "  'HASS',\n",
    "  'BAG',\n",
    "  '4CT',\n",
    "  'A',\n",
    "  'APPLE',\n",
    "  'BAG',\n",
    "  'JAZZ',\n",
    "  '2',\n",
    "  'LB',\n",
    "  'A',\n",
    "  'PEPPER',\n",
    "  'BELL',\n",
    "  'EACH',\n",
    "  'XL',\n",
    "  'RED',\n",
    "  'GROCERY',\n",
    "  'NON',\n",
    "  'TAXABLE',\n",
    "  'BANANAS',\n",
    "  'ORGANIC',\n",
    "  'CREAMY',\n",
    "  'SALTED',\n",
    "  'PEANUT',\n",
    "  'BUTTER',\n",
    "  'WHL',\n",
    "  'WHT',\n",
    "  'PITA',\n",
    "  'BREAD',\n",
    "  'GROCERY',\n",
    "  'NON',\n",
    "  'TAXABLE'],\n",
    " ['GV', 'OATMEAL', 'OT', '200Z', 'TUM', 'M', 'ATHLETICS', 'DEXAS', '15X20'],\n",
    " ['TATER',\n",
    "  'TOTS',\n",
    "  'HARD',\n",
    "  'PROV',\n",
    "  'DC',\n",
    "  'SNACK',\n",
    "  'BARS',\n",
    "  'HRI',\n",
    "  'CL',\n",
    "  'CHS',\n",
    "  'HRI',\n",
    "  'CL',\n",
    "  'CHS',\n",
    "  'HRI',\n",
    "  'CL',\n",
    "  'CHS',\n",
    "  'HRI',\n",
    "  '12',\n",
    "  'U',\n",
    "  'SG',\n",
    "  'HRI',\n",
    "  'CL',\n",
    "  'PEP',\n",
    "  'EARBUDS',\n",
    "  'SC',\n",
    "  'BCN',\n",
    "  'CHDDR',\n",
    "  'ABF',\n",
    "  'THINBRST',\n",
    "  'ABF',\n",
    "  'THINBRST',\n",
    "  'HARD',\n",
    "  'PROV',\n",
    "  'DC',\n",
    "  'DV',\n",
    "  'RSE',\n",
    "  'OIL',\n",
    "  'M',\n",
    "  'APPLE',\n",
    "  '3',\n",
    "  'BAG',\n",
    "  'STOK',\n",
    "  'LT',\n",
    "  'SWT',\n",
    "  'PEANUT',\n",
    "  'BUTTER',\n",
    "  'AVO',\n",
    "  'VERDE',\n",
    "  'ROLLS',\n",
    "  'BTS',\n",
    "  'DRY',\n",
    "  'BLON',\n",
    "  'GALE',\n",
    "  'TR',\n",
    "  'HS',\n",
    "  'FRM',\n",
    "  '4',\n",
    "  'BAGELS',\n",
    "  'GV',\n",
    "  'SLIDERS',\n",
    "  'ACCESSORY',\n",
    "  'CHEEZE',\n",
    "  'IT',\n",
    "  'RITZ',\n",
    "  'RUFFLES',\n",
    "  'GV',\n",
    "  'HNY',\n",
    "  'GRMS'],\n",
    " ['SW', 'HRO', 'FGHTR'],\n",
    " ['KTTL',\n",
    "  'SEA',\n",
    "  'SALT',\n",
    "  'POT',\n",
    "  'CHP',\n",
    "  'BRAIDED',\n",
    "  'BRIOCHE',\n",
    "  'CHEF',\n",
    "  'PLATE',\n",
    "  'MEAL'],\n",
    " ['Woman',\n",
    "  'Ham',\n",
    "  'Cheese',\n",
    "  'Ice',\n",
    "  'Java',\n",
    "  'Tea',\n",
    "  'Mineral',\n",
    "  'Water',\n",
    "  'Black',\n",
    "  '&',\n",
    "  'White'],\n",
    " ['6', 'WING', 'PLATE', 'ASST', '27', 'CUTIE', 'CAR'],\n",
    " ['FF',\n",
    "  'BS',\n",
    "  'BREAST',\n",
    "  'KS',\n",
    "  'DICED',\n",
    "  'TOM',\n",
    "  'JACKORGSALSE',\n",
    "  '18CT',\n",
    "  'EGGS',\n",
    "  'GRAPE',\n",
    "  'TOMATO',\n",
    "  'ECO',\n",
    "  'HALF',\n",
    "  'PAN',\n",
    "  'GRND',\n",
    "  'TURKEY',\n",
    "  'CHPD',\n",
    "  'ONION',\n",
    "  'MONT',\n",
    "  'JACK',\n",
    "  '2#'],\n",
    " ['N',\n",
    "  'YORK',\n",
    "  'TX',\n",
    "  'GRLC',\n",
    "  'CHICKEN',\n",
    "  'WINGS',\n",
    "  'PICSWEET',\n",
    "  'BLEND',\n",
    "  'PICSWEET',\n",
    "  'GREENS',\n",
    "  'CHICKEN',\n",
    "  'WINGS',\n",
    "  'DIET',\n",
    "  'LN',\n",
    "  'GRND',\n",
    "  'B',\n",
    "  'PORK',\n",
    "  'LOIN',\n",
    "  'CHOP',\n",
    "  'DRUMSTICKS',\n",
    "  'EYE',\n",
    "  'RND',\n",
    "  'STK',\n",
    "  'FP',\n",
    "  'EYE',\n",
    "  'RND',\n",
    "  'STK',\n",
    "  'FP',\n",
    "  'BEEF',\n",
    "  'FOR',\n",
    "  'STEW',\n",
    "  'PORK',\n",
    "  '1',\n",
    "  '2',\n",
    "  'LOIN',\n",
    "  'B',\n",
    "  'BEST',\n",
    "  'S',\n",
    "  'STEAK',\n",
    "  'BAR',\n",
    "  'S',\n",
    "  'MEAT',\n",
    "  'FRNK',\n",
    "  '0',\n",
    "  'M',\n",
    "  'HAM',\n",
    "  'WINCO',\n",
    "  'NOODLES',\n",
    "  'TNDRBRD',\n",
    "  'CHIX',\n",
    "  'BR',\n",
    "  'KRFT',\n",
    "  'DELUXE',\n",
    "  'MAC',\n",
    "  'EGGO',\n",
    "  'WAFFLE',\n",
    "  'L',\n",
    "  'D',\n",
    "  'NUTTY',\n",
    "  'BARS',\n",
    "  'L',\n",
    "  'D',\n",
    "  'OATMEAL',\n",
    "  'CRM',\n",
    "  'LINKS',\n",
    "  'MILD',\n",
    "  'KEEB',\n",
    "  'TOWNHOUSE',\n",
    "  'TURKEY',\n",
    "  'FRANK',\n",
    "  'RESERS',\n",
    "  'POT',\n",
    "  'SLD',\n",
    "  'DM',\n",
    "  'SPAG',\n",
    "  'SAUCE',\n",
    "  'HUNTS',\n",
    "  'MANWICH',\n",
    "  'DM',\n",
    "  'PNAPL',\n",
    "  'CHNKY',\n",
    "  'SUNBEAN',\n",
    "  'BUNS',\n",
    "  'WINCO',\n",
    "  'SNDWCH',\n",
    "  'WT',\n",
    "  'WINCO',\n",
    "  'HOMO',\n",
    "  'MILK',\n",
    "  'EGGS'],\n",
    " ['LAZENBY',\n",
    "  'WORCESTER',\n",
    "  'SAUCE',\n",
    "  'MILKY',\n",
    "  'BAR',\n",
    "  'CHOC',\n",
    "  'SMOKED',\n",
    "  'VIENNAS',\n",
    "  'PEALED',\n",
    "  'PEACHES',\n",
    "  'MEDITERRANEAN',\n",
    "  'MIX',\n",
    "  'SPAR',\n",
    "  'COOKING',\n",
    "  'OIL',\n",
    "  'F',\n",
    "  'L',\n",
    "  'ENGLISH',\n",
    "  'CUCUMB',\n",
    "  'NESTLE',\n",
    "  'AERO',\n",
    "  'CADBURY',\n",
    "  'DAIRY',\n",
    "  'MI',\n",
    "  'GRAPES',\n",
    "  'MIXED',\n",
    "  'TUB',\n",
    "  'TASTIC',\n",
    "  'RICE',\n",
    "  'BLACK',\n",
    "  'CAT',\n",
    "  'SMOOTH',\n",
    "  'CARRIER',\n",
    "  'BAG',\n",
    "  '24L',\n",
    "  'BANANAS',\n",
    "  'LOOSE'],\n",
    " ['PL',\n",
    "  \"TORTILLA'S\",\n",
    "  'CAGE',\n",
    "  'FREE',\n",
    "  'ALL',\n",
    "  'WHIT',\n",
    "  'BLACK',\n",
    "  'BEANS',\n",
    "  'Frozen',\n",
    "  'Mangoes',\n",
    "  '16o',\n",
    "  'Whole',\n",
    "  'Strawberries',\n",
    "  'OG',\n",
    "  'LF',\n",
    "  'COTTAGE',\n",
    "  'CHEE',\n",
    "  'MAHI',\n",
    "  'MAHI',\n",
    "  'FILLETS',\n",
    "  '$2',\n",
    "  'off',\n",
    "  '(1)',\n",
    "  'WC',\n",
    "  'Fill',\n",
    "  'California',\n",
    "  'Harvest',\n",
    "  'PLUMS',\n",
    "  'BLACK',\n",
    "  'CV'],\n",
    " ['SW', 'FIGURES', 'TOOTHBRUSH', 'WOMEN', 'SLIPPE'],\n",
    " ['GIFT', 'CARD'],\n",
    " ['EQUATE',\n",
    "  'LINER',\n",
    "  'VFUS',\n",
    "  'ENG',\n",
    "  'POM',\n",
    "  'DAWN',\n",
    "  'ORIG',\n",
    "  '50YD',\n",
    "  'PKGTAPE',\n",
    "  '50YD',\n",
    "  'PKGTAPE',\n",
    "  'LINT',\n",
    "  'POLLER2'],\n",
    " ['DIABETES'],\n",
    " ['6', 'WING', 'PLATE', 'ASST', '27', 'CUTIE', 'CAR'],\n",
    " ['BANANAS',\n",
    "  'BEVERAGE',\n",
    "  'OS',\n",
    "  'CRAN',\n",
    "  'POM',\n",
    "  'STRWBRY',\n",
    "  'CC',\n",
    "  'CAMPARI',\n",
    "  'TOM',\n",
    "  'KFT',\n",
    "  'SINGLES',\n",
    "  'HARD',\n",
    "  'SALAMI',\n",
    "  'AVOCADO',\n",
    "  'PILLS',\n",
    "  'WHITE',\n",
    "  'SH',\n",
    "  'NYLON',\n",
    "  'COL',\n",
    "  'HAND',\n",
    "  'CLEANER',\n",
    "  'INJECTR',\n",
    "  'CLNR'],\n",
    " ['GV',\n",
    "  'WATER',\n",
    "  'GV',\n",
    "  'WATER',\n",
    "  'GREAT',\n",
    "  'VALUE',\n",
    "  'GREAT',\n",
    "  'VALUE',\n",
    "  'GAIN',\n",
    "  'LFE',\n",
    "  'GAIN',\n",
    "  'GV',\n",
    "  'VEG',\n",
    "  'OIL',\n",
    "  'SNICKER',\n",
    "  'FS',\n",
    "  'GDBR',\n",
    "  'FS',\n",
    "  '6PK',\n",
    "  'MIXED',\n",
    "  'CHOC',\n",
    "  'CHERRIES',\n",
    "  'GAIN',\n",
    "  'HY',\n",
    "  'PSTLEG',\n",
    "  'PM',\n",
    "  'BATTERIES',\n",
    "  'GV',\n",
    "  '20Z',\n",
    "  'MINI',\n",
    "  'CRNBRY',\n",
    "  'SAUCE',\n",
    "  'SPREADS',\n",
    "  'EGGS',\n",
    "  '6CT'],\n",
    " ['GRILL', 'COVER', 'FIBER', 'CHOICE', 'CELERY', 'HEART', 'RED', 'GRAPE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_trocr_lines(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    width, height = image.size\n",
    "\n",
    "    # Разбиваем изображение на строки\n",
    "    line_height = 40  # Высота строки (можно подобрать)\n",
    "    texts = []\n",
    "\n",
    "    for y in range(0, height, line_height):\n",
    "        cropped_line = image.crop((0, y, width, min(y + line_height, height)))\n",
    "        pixel_values = processor(images=cropped_line, return_tensors=\"pt\").pixel_values\n",
    "        \n",
    "        generated_ids = model.generate(pixel_values)\n",
    "        line_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        if line_text.strip():\n",
    "            texts.append(line_text)\n",
    "\n",
    "    return \" \".join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>recognized_text</th>\n",
       "      <th>processing_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[BANANAS, FRAP]</td>\n",
       "      <td>- CASHIER CASHIER - ........ WALMART ALWAYS LO...</td>\n",
       "      <td>45.765995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[R-CARROTS SHREDDED 10 OZ, R-CUCUMBERS PERSIAN...</td>\n",
       "      <td>THANK YOU FOR FULL WWW. *** TRADER JOE'S AMOUN...</td>\n",
       "      <td>72.264516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[GV OATMEAL, OT 200Z TUM, M ATHLETICS, DEXAS 1...</td>\n",
       "      <td>AMOUNT THANK YOU! ID #: 788504072,WALMART.COM ...</td>\n",
       "      <td>52.375142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[TATER TOTS, HARD/PROV/DC, SNACK BARS, HRI CL ...</td>\n",
       "      <td>AMOUNT AMOUNT AMOUNT AMOUNT NO WIN ST000 TEEN ...</td>\n",
       "      <td>64.085966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[SW HRO FGHTR]</td>\n",
       "      <td>WALMARKU SAVE MONEY.LIVEBETTER. 1 (8) PLEASE S...</td>\n",
       "      <td>37.956999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[KTTL SEA SALT POT CHP, BRAIDED BRIOCHE, CHEF ...</td>\n",
       "      <td>WWW. CASHIER NO: 5:00 PM WWW.LA.COM SR007 AD |...</td>\n",
       "      <td>321.784266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[Woman, Ham Cheese, Ice Java Tea, Mineral Wate...</td>\n",
       "      <td>AMOUNT ITEMS MOMLATOVE *** CREPERIE CASHIER AM...</td>\n",
       "      <td>97.640744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[6 WING PLATE, ASST 27, CUTIE CAR]</td>\n",
       "      <td>1 1 WWWWWWWWWWWWWWWW. PLEASE TO WIN $1000 RECE...</td>\n",
       "      <td>99.018761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[FF BS BREAST, KS DICED TOM, JACKORGSALSE, 18C...</td>\n",
       "      <td>WW.SALBOVE. SR: COSTCO - 16375 N. WASHINSTON S...</td>\n",
       "      <td>63.131017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[N/YORK TX GRLC, CHICKEN WINGS, PICSWEET BLEND...</td>\n",
       "      <td>THANK YOU FOR A FREE - - AM WINCO SR: *** *** ...</td>\n",
       "      <td>83.370610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "1  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "2  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "3  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "4  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "5  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "6  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "7  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "8  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "9  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0                                    [BANANAS, FRAP]   \n",
       "1  [R-CARROTS SHREDDED 10 OZ, R-CUCUMBERS PERSIAN...   \n",
       "2  [GV OATMEAL, OT 200Z TUM, M ATHLETICS, DEXAS 1...   \n",
       "3  [TATER TOTS, HARD/PROV/DC, SNACK BARS, HRI CL ...   \n",
       "4                                     [SW HRO FGHTR]   \n",
       "5  [KTTL SEA SALT POT CHP, BRAIDED BRIOCHE, CHEF ...   \n",
       "6  [Woman, Ham Cheese, Ice Java Tea, Mineral Wate...   \n",
       "7                 [6 WING PLATE, ASST 27, CUTIE CAR]   \n",
       "8  [FF BS BREAST, KS DICED TOM, JACKORGSALSE, 18C...   \n",
       "9  [N/YORK TX GRLC, CHICKEN WINGS, PICSWEET BLEND...   \n",
       "\n",
       "                                     recognized_text  processing_time  \n",
       "0  - CASHIER CASHIER - ........ WALMART ALWAYS LO...        45.765995  \n",
       "1  THANK YOU FOR FULL WWW. *** TRADER JOE'S AMOUN...        72.264516  \n",
       "2  AMOUNT THANK YOU! ID #: 788504072,WALMART.COM ...        52.375142  \n",
       "3  AMOUNT AMOUNT AMOUNT AMOUNT NO WIN ST000 TEEN ...        64.085966  \n",
       "4  WALMARKU SAVE MONEY.LIVEBETTER. 1 (8) PLEASE S...        37.956999  \n",
       "5  WWW. CASHIER NO: 5:00 PM WWW.LA.COM SR007 AD |...       321.784266  \n",
       "6  AMOUNT ITEMS MOMLATOVE *** CREPERIE CASHIER AM...        97.640744  \n",
       "7  1 1 WWWWWWWWWWWWWWWW. PLEASE TO WIN $1000 RECE...        99.018761  \n",
       "8  WW.SALBOVE. SR: COSTCO - 16375 N. WASHINSTON S...        63.131017  \n",
       "9  THANK YOU FOR A FREE - - AM WINCO SR: *** *** ...        83.370610  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(int(len(valid_data) / 2)):\n",
    "    image_path = f'{path}/images/{i}.jpg'\n",
    "\n",
    "    start_time = time.time()\n",
    "    recognized_text = extract_text_trocr_lines(image_path)\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    results.append({\n",
    "        \"image_path\": image_path,\n",
    "        \"ground_truth\": valid_data[i],\n",
    "        \"recognized_text\": recognized_text,\n",
    "        \"processing_time\": processing_time,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0:\n",
      "  Precision: 1.52%\n",
      "  Recall: 50.00%\n",
      "  F1-Score: 2.94%\n",
      "  Accuracy: 50.00%\n",
      "  Time: 83.37060976028442\n",
      "------------------------------\n",
      "Image 1:\n",
      "  Precision: 12.36%\n",
      "  Recall: 18.64%\n",
      "  F1-Score: 14.86%\n",
      "  Accuracy: 14.67%\n",
      "  Time: 83.37060976028442\n",
      "------------------------------\n",
      "Image 2:\n",
      "  Precision: 0.00%\n",
      "  Recall: 0.00%\n",
      "  F1-Score: 0.00%\n",
      "  Accuracy: 0.00%\n",
      "  Time: 83.37060976028442\n",
      "------------------------------\n",
      "Image 3:\n",
      "  Precision: 1.75%\n",
      "  Recall: 1.89%\n",
      "  F1-Score: 1.82%\n",
      "  Accuracy: 1.47%\n",
      "  Time: 83.37060976028442\n",
      "------------------------------\n",
      "Image 4:\n",
      "  Precision: 0.00%\n",
      "  Recall: 0.00%\n",
      "  F1-Score: 0.00%\n",
      "  Accuracy: 0.00%\n",
      "  Time: 83.37060976028442\n",
      "------------------------------\n",
      "Image 5:\n",
      "  Precision: 0.82%\n",
      "  Recall: 20.00%\n",
      "  F1-Score: 1.57%\n",
      "  Accuracy: 20.00%\n",
      "  Time: 83.37060976028442\n",
      "------------------------------\n",
      "Image 6:\n",
      "  Precision: 5.13%\n",
      "  Recall: 36.36%\n",
      "  F1-Score: 8.99%\n",
      "  Accuracy: 36.36%\n",
      "  Time: 83.37060976028442\n",
      "------------------------------\n",
      "Image 7:\n",
      "  Precision: 4.44%\n",
      "  Recall: 57.14%\n",
      "  F1-Score: 8.25%\n",
      "  Accuracy: 57.14%\n",
      "  Time: 83.37060976028442\n",
      "------------------------------\n",
      "Image 8:\n",
      "  Precision: 10.53%\n",
      "  Recall: 38.10%\n",
      "  F1-Score: 16.49%\n",
      "  Accuracy: 38.10%\n",
      "  Time: 83.37060976028442\n",
      "------------------------------\n",
      "Image 9:\n",
      "  Precision: 7.53%\n",
      "  Recall: 9.46%\n",
      "  F1-Score: 8.38%\n",
      "  Accuracy: 7.78%\n",
      "  Time: 83.37060976028442\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    return text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def calculate_accuracy(recognized: List[str], valid: List[str]) -> dict:\n",
    "    recognized_set = {normalize_text(word) for word in recognized}\n",
    "    valid_set = {normalize_text(word) for word in valid}\n",
    "    \n",
    "    true_positives = len(recognized_set & valid_set)\n",
    "    false_positives = len(recognized_set - valid_set)\n",
    "    false_negatives = len(valid_set - recognized_set)\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if recognized_set else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if valid_set else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision * 100,\n",
    "        \"recall\": recall * 100,\n",
    "        \"f1_score\": f1_score * 100,\n",
    "        \"accuracy\": (true_positives / len(valid)) * 100 if valid else 0\n",
    "    }\n",
    "\n",
    "for i in range(int(len(valid_data) / 2)):\n",
    "    metrics = calculate_accuracy(results_df['recognized_text'][i].split(), valid_data[i])\n",
    "    print(f'Image {i}:')\n",
    "    print(f\"  Precision: {metrics['precision']:.2f}%\")\n",
    "    print(f\"  Recall: {metrics['recall']:.2f}%\")\n",
    "    print(f\"  F1-Score: {metrics['f1_score']:.2f}%\")\n",
    "    print(f\"  Accuracy: {metrics['accuracy']:.2f}%\")\n",
    "    print(f\"  Time: {end_time - start_time}\")\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
