{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gta76\\desktop\\project\\ml-project\\.venv\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ---------------------------------------  10.0/10.1 MB 61.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 48.4 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Downloading safetensors-0.4.5-cp310-none-win_amd64.whl (285 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 45.3 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 safetensors-0.4.5 tokenizers-0.21.0 transformers-4.47.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import time\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from typing import List\n",
    "import string\n",
    "\n",
    "path = kagglehub.dataset_download(\"trainingdatapro/ocr-receipts-text-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gta76\\Desktop\\project\\ml-project\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\gta76\\.cache\\huggingface\\hub\\models--microsoft--trocr-base-printed. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.47.1\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = [\n",
    "    ['BANANAS', 'FRAP'],\n",
    "    ['R-CARROTS SHREDDED 10 OZ', 'R-CUCUMBERS PERSIAN 1 LB', 'TOMATOES CRUSHED NO SALT', 'TOMATOES WHOLE NO SALT W/BASIL', \n",
    "     'ORGANIC OLD FASHIONED OATMEAL', 'MINI-PEARL TOMATOES..', 'PKG SHREDDED MOZZARELLA LITE T', 'EGGS 1 DOZ ORGANIC BROWN.', \n",
    "     'BEANS GARBANZO', 'SPROUTED CA STYLE', 'A-AVOCADOS HASS BAG 4CT', 'A-APPLE BAG JAZZ 2 LB', 'A-PEPPER BELL EACH XL RED', \n",
    "     'GROCERY NON TAXABLE', 'BANANAS ORGANIC', 'CREAMY SALTED PEANUT BUTTER', 'WHL WHT PITA BREAD', 'GROCERY NON TAXABLE'],\n",
    "    ['GV OATMEAL', 'OT 200Z TUM', 'M ATHLETICS', 'DEXAS 15X20'],\n",
    "    ['TATER TOTS', 'HARD/PROV/DC', 'SNACK BARS', 'HRI CL CHS', 'HRI CL CHS', 'HRI CL CHS', 'HRI 12 U SG', 'HRI CL PEP', 'EARBUDS',\n",
    "      'SC BCN CHDDR', 'ABF THINBRST', 'ABF THINBRST', 'HARD/PROV/DC', 'DV RSE OIL M', 'APPLE 3 BAG', 'STOK LT SWT', 'PEANUT BUTTER',\n",
    "      'AVO VERDE', 'ROLLS', 'BTS DRY BLON', 'GALE', 'TR HS FRM 4', 'BAGELS', 'GV SLIDERS', 'ACCESSORY', 'CHEEZE IT', 'RITZ', 'RUFFLES', 'GV HNY GRMS'],\n",
    "    ['SW HRO FGHTR'],\n",
    "    ['KTTL SEA SALT POT CHP', 'BRAIDED BRIOCHE', 'CHEF PLATE MEAL'],\n",
    "    ['Woman', 'Ham Cheese', 'Ice Java Tea', 'Mineral Water', 'Black & White'],\n",
    "    ['6 WING PLATE', 'ASST 27', 'CUTIE CAR'],\n",
    "    ['FF BS BREAST', 'KS DICED TOM', 'JACKORGSALSE', '18CT EGGS', 'GRAPE TOMATO', 'ECO HALF PAN', 'GRND TURKEY', 'CHPD ONION', 'MONT JACK 2#'],\n",
    "    ['N/YORK TX GRLC', 'CHICKEN WINGS', 'PICSWEET BLEND', 'PICSWEET GREENS', 'CHICKEN WINGS', 'DIET LN GRND B', 'PORK LOIN CHOP', 'DRUMSTICKS',\n",
    "     'EYE RND STK FP', 'EYE RND STK FP', 'BEEF FOR STEW', 'PORK 1/2 LOIN', 'B/BEST S STEAK', 'BAR S MEAT FRNK', '0/M HAM', 'WINCO NOODLES', 'TNDRBRD CHIX BR'\n",
    "     'KRFT DELUXE MAC', 'EGGO WAFFLE', 'L/D NUTTY BARS', 'L\\D OATMEAL CRM', 'LINKS MILD', 'KEEB TOWNHOUSE', 'TURKEY FRANK', 'RESERS POT SLD', 'DM SPAG SAUCE',\n",
    "     'HUNTS MANWICH', 'DM PNAPL CHNKY', 'SUNBEAN BUNS', 'WINCO SNDWCH WT', 'WINCO HOMO MILK', 'EGGS'],\n",
    "    ['LAZENBY WORCESTER SAUCE', 'MILKY BAR CHOC', 'SMOKED VIENNAS', 'PEALED PEACHES', 'MEDITERRANEAN MIX', 'SPAR COOKING OIL',\n",
    "     'F/L ENGLISH CUCUMB', 'NESTLE AERO', 'CADBURY DAIRY MI', 'GRAPES MIXED TUB', 'TASTIC RICE', 'BLACK CAT SMOOTH', 'CARRIER BAG 24L', 'BANANAS LOOSE'],\n",
    "    [\"PL TORTILLA'S\", 'CAGE FREE ALL WHIT', 'BLACK BEANS', 'Frozen Mangoes 16o', 'Whole Strawberries', 'OG LF COTTAGE CHEE', 'MAHI MAHI FILLETS', '$2 off (1) WC Fill',\n",
    "     'California Harvest', 'PLUMS BLACK CV'],\n",
    "    ['SW FIGURES', 'TOOTHBRUSH', 'WOMEN SLIPPE'],\n",
    "    ['GIFT CARD'],\n",
    "    ['EQUATE LINER', 'VFUS ENG POM', 'DAWN ORIG', '50YD PKGTAPE', '50YD PKGTAPE', 'LINT POLLER2'],\n",
    "    ['DIABETES'],\n",
    "    ['6 WING PLATE', 'ASST 27', 'CUTIE CAR'],\n",
    "    ['BANANAS', 'BEVERAGE', 'OS CRAN POM', 'STRWBRY CC', 'CAMPARI TOM', 'KFT SINGLES', 'HARD SALAMI', 'AVOCADO', 'PILLS WHITE', 'SH NYLON COL', 'HAND CLEANER', 'INJECTR CLNR'],\n",
    "    ['GV WATER', 'GV WATER', 'GREAT VALUE', 'GREAT VALUE', 'GAIN LFE', 'GAIN', 'GV VEG OIL', 'SNICKER FS', 'GDBR FS 6PK', 'MIXED CHOC', 'CHERRIES', 'GAIN', 'HY PSTLEG PM',\n",
    "     'BATTERIES', 'GV 20Z MINI', 'CRNBRY SAUCE', 'SPREADS', 'EGGS 6CT'],\n",
    "    ['GRILL COVER', 'FIBER CHOICE', 'CELERY HEART', 'RED GRAPE'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_trocr_lines(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    width, height = image.size\n",
    "\n",
    "    # Разбиваем изображение на строки\n",
    "    line_height = 40  # Высота строки (можно подобрать)\n",
    "    texts = []\n",
    "\n",
    "    for y in range(0, height, line_height):\n",
    "        cropped_line = image.crop((0, y, width, min(y + line_height, height)))\n",
    "        pixel_values = processor(images=cropped_line, return_tensors=\"pt\").pixel_values\n",
    "        \n",
    "        generated_ids = model.generate(pixel_values)\n",
    "        line_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        if line_text.strip():\n",
    "            texts.append(line_text)\n",
    "\n",
    "    return \" \".join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>recognized_text</th>\n",
       "      <th>processing_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[BANANAS, FRAP]</td>\n",
       "      <td>- CASHIER CASHIER - ........ WALMART ALWAYS LO...</td>\n",
       "      <td>45.765995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[R-CARROTS SHREDDED 10 OZ, R-CUCUMBERS PERSIAN...</td>\n",
       "      <td>THANK YOU FOR FULL WWW. *** TRADER JOE'S AMOUN...</td>\n",
       "      <td>72.264516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[GV OATMEAL, OT 200Z TUM, M ATHLETICS, DEXAS 1...</td>\n",
       "      <td>AMOUNT THANK YOU! ID #: 788504072,WALMART.COM ...</td>\n",
       "      <td>52.375142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[TATER TOTS, HARD/PROV/DC, SNACK BARS, HRI CL ...</td>\n",
       "      <td>AMOUNT AMOUNT AMOUNT AMOUNT NO WIN ST000 TEEN ...</td>\n",
       "      <td>64.085966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[SW HRO FGHTR]</td>\n",
       "      <td>WALMARKU SAVE MONEY.LIVEBETTER. 1 (8) PLEASE S...</td>\n",
       "      <td>37.956999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[KTTL SEA SALT POT CHP, BRAIDED BRIOCHE, CHEF ...</td>\n",
       "      <td>WWW. CASHIER NO: 5:00 PM WWW.LA.COM SR007 AD |...</td>\n",
       "      <td>321.784266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[Woman, Ham Cheese, Ice Java Tea, Mineral Wate...</td>\n",
       "      <td>AMOUNT ITEMS MOMLATOVE *** CREPERIE CASHIER AM...</td>\n",
       "      <td>97.640744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[6 WING PLATE, ASST 27, CUTIE CAR]</td>\n",
       "      <td>1 1 WWWWWWWWWWWWWWWW. PLEASE TO WIN $1000 RECE...</td>\n",
       "      <td>99.018761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[FF BS BREAST, KS DICED TOM, JACKORGSALSE, 18C...</td>\n",
       "      <td>WW.SALBOVE. SR: COSTCO - 16375 N. WASHINSTON S...</td>\n",
       "      <td>63.131017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...</td>\n",
       "      <td>[N/YORK TX GRLC, CHICKEN WINGS, PICSWEET BLEND...</td>\n",
       "      <td>THANK YOU FOR A FREE - - AM WINCO SR: *** *** ...</td>\n",
       "      <td>83.370610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path  \\\n",
       "0  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "1  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "2  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "3  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "4  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "5  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "6  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "7  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "8  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "9  C:\\Users\\gta76\\.cache\\kagglehub\\datasets\\train...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0                                    [BANANAS, FRAP]   \n",
       "1  [R-CARROTS SHREDDED 10 OZ, R-CUCUMBERS PERSIAN...   \n",
       "2  [GV OATMEAL, OT 200Z TUM, M ATHLETICS, DEXAS 1...   \n",
       "3  [TATER TOTS, HARD/PROV/DC, SNACK BARS, HRI CL ...   \n",
       "4                                     [SW HRO FGHTR]   \n",
       "5  [KTTL SEA SALT POT CHP, BRAIDED BRIOCHE, CHEF ...   \n",
       "6  [Woman, Ham Cheese, Ice Java Tea, Mineral Wate...   \n",
       "7                 [6 WING PLATE, ASST 27, CUTIE CAR]   \n",
       "8  [FF BS BREAST, KS DICED TOM, JACKORGSALSE, 18C...   \n",
       "9  [N/YORK TX GRLC, CHICKEN WINGS, PICSWEET BLEND...   \n",
       "\n",
       "                                     recognized_text  processing_time  \n",
       "0  - CASHIER CASHIER - ........ WALMART ALWAYS LO...        45.765995  \n",
       "1  THANK YOU FOR FULL WWW. *** TRADER JOE'S AMOUN...        72.264516  \n",
       "2  AMOUNT THANK YOU! ID #: 788504072,WALMART.COM ...        52.375142  \n",
       "3  AMOUNT AMOUNT AMOUNT AMOUNT NO WIN ST000 TEEN ...        64.085966  \n",
       "4  WALMARKU SAVE MONEY.LIVEBETTER. 1 (8) PLEASE S...        37.956999  \n",
       "5  WWW. CASHIER NO: 5:00 PM WWW.LA.COM SR007 AD |...       321.784266  \n",
       "6  AMOUNT ITEMS MOMLATOVE *** CREPERIE CASHIER AM...        97.640744  \n",
       "7  1 1 WWWWWWWWWWWWWWWW. PLEASE TO WIN $1000 RECE...        99.018761  \n",
       "8  WW.SALBOVE. SR: COSTCO - 16375 N. WASHINSTON S...        63.131017  \n",
       "9  THANK YOU FOR A FREE - - AM WINCO SR: *** *** ...        83.370610  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(int(len(valid_data) / 2)):\n",
    "    image_path = f'{path}/images/{i}.jpg'\n",
    "\n",
    "    start_time = time.time()\n",
    "    recognized_text = extract_text_trocr_lines(image_path)\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "    \n",
    "    results.append({\n",
    "        \"image_path\": image_path,\n",
    "        \"ground_truth\": valid_data[i],\n",
    "        \"recognized_text\": recognized_text,\n",
    "        \"processing_time\": processing_time,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 1.5151515151515151, 'recall': 50.0, 'f1_score': 2.9411764705882355, 'accuracy': 50.0}\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'accuracy': 0.0}\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'accuracy': 0.0}\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'accuracy': 0.0}\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'accuracy': 0.0}\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'accuracy': 0.0}\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'accuracy': 0.0}\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'accuracy': 0.0}\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'accuracy': 0.0}\n",
      "{'precision': 0.0, 'recall': 0.0, 'f1_score': 0, 'accuracy': 0.0}\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    return text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def calculate_accuracy(recognized: List[str], valid: List[str]) -> dict:\n",
    "    recognized_set = {normalize_text(word) for word in recognized}\n",
    "    valid_set = {normalize_text(word) for word in valid}\n",
    "    \n",
    "    true_positives = len(recognized_set & valid_set)\n",
    "    false_positives = len(recognized_set - valid_set)\n",
    "    false_negatives = len(valid_set - recognized_set)\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if recognized_set else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if valid_set else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision * 100,\n",
    "        \"recall\": recall * 100,\n",
    "        \"f1_score\": f1_score * 100,\n",
    "        \"accuracy\": (true_positives / len(valid)) * 100 if valid else 0\n",
    "    }\n",
    "\n",
    "for i in range(int(len(valid_data) / 2)):\n",
    "    print(calculate_accuracy(results_df['recognized_text'][i].split(), valid_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
